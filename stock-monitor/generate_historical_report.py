#!/usr/bin/env python3
"""
ç”Ÿæˆ2026å¹´1æœˆ1æ—¥è‡³ç°åœ¨çš„å†å²æ•°æ®æŠ¥è¡¨åˆ°Notion

âš ï¸ å·²å¼ƒç”¨: æ­¤è„šæœ¬ä½¿ç”¨æ—§çš„æ•°æ®è·å–å™¨ï¼Œå»ºè®®ä½¿ç”¨ run_multi_market.py
"""
import sys
import asyncio
sys.path.insert(0, '.')

import logging
from datetime import datetime, timedelta
from src.config import get_settings
from src.data_fetchers import DataFetcherFactory, MarketType
from src.analyzer import SectorAnalyzer
from src.chart_generator import ChartGenerator
from src.notion_writer import NotionWriter

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

async def generate_historical_report():
    """ç”Ÿæˆå†å²æ•°æ®æŠ¥è¡¨"""
    
    settings = get_settings()
    
    # åˆå§‹åŒ–ç»„ä»¶ - ä½¿ç”¨ DataFetcherFactory
    fetcher = DataFetcherFactory.create(MarketType.A_SHARE)
    analyzer = SectorAnalyzer(data_path=settings.DATA_PATH)
    chart_gen = ChartGenerator(data_path=settings.DATA_PATH, charts_path='./charts')
    notion = NotionWriter(
        api_key=settings.NOTION_API_KEY,
        parent_page_id=settings.NOTION_PARENT_PAGE_ID
    )
    
    # æ—¥æœŸèŒƒå›´ï¼š2026å¹´1æœˆ1æ—¥åˆ°ç°åœ¨
    start_date = '2026-01-01'
    end_date = datetime.now().strftime('%Y-%m-%d')
    
    logger.info(f"=" * 60)
    logger.info(f"ç”Ÿæˆå†å²æ•°æ®æŠ¥è¡¨: {start_date} è‡³ {end_date}")
    logger.info(f"=" * 60)
    
    # 1. è·å–ä»Šæ—¥æ¿å—åˆ—è¡¨ï¼ˆç”¨äºç¡®å®šè¦è·å–å†å²çš„æ¿å—ï¼‰
    logger.info("è·å–å½“å‰æ¿å—åˆ—è¡¨...")
    today_df = fetcher.get_sector_data()
    top_sectors = today_df.nlargest(20, 'main_inflow')['sector_name'].tolist()
    logger.info(f"å…³æ³¨æ¿å—: {', '.join(top_sectors[:10])}...")
    
    # 2. å›å¡«å†å²æ•°æ®
    logger.info(f"\nå›å¡«å†å²æ•°æ®ï¼ˆ{start_date} è‡³ {end_date}ï¼‰...")
    historical_df = fetcher.backfill_historical_data(
        sectors=top_sectors[:15],  # å‰15ä¸ªæ¿å—ï¼Œé¿å…è¯·æ±‚è¿‡å¤š
        end_date=end_date,
        days=47  # 1æœˆ1æ—¥åˆ°2æœˆ16æ—¥çº¦47å¤©
    )
    
    if historical_df.empty:
        logger.error("æœªèƒ½è·å–å†å²æ•°æ®")
        return False
    
    logger.info(f"è·å–åˆ° {len(historical_df)} æ¡å†å²è®°å½•")
    logger.info(f"æ—¥æœŸèŒƒå›´: {historical_df['date'].min()} è‡³ {historical_df['date'].max()}")
    
    # 3. ä¿å­˜æ•°æ®å¿«ç…§
    logger.info("\nä¿å­˜æ•°æ®åˆ°CSV...")
    for date in historical_df['date'].unique():
        day_data = historical_df[historical_df['date'] == date]
        analyzer.save_snapshot(day_data, date)
    
    # 4. è®¡ç®—å„æ¿å—è¶‹åŠ¿
    logger.info("\nåˆ†ææ¿å—è¶‹åŠ¿...")
    trend_results = []
    
    for sector in top_sectors[:15]:
        try:
            trend = analyzer.calculate_trend_strength(historical_df, sector, days=10)
            if trend and 'error' not in trend:
                trend_results.append({
                    'sector': sector,
                    'trend_score': float(trend['trend_score']),
                    'direction': trend['trend_direction'],
                    'avg_inflow': float(trend['avg_inflow']),
                    'consistency': float(trend['consistency']),
                    'momentum': float(trend['momentum'])
                })
        except Exception as e:
            logger.warning(f"è®¡ç®— {sector} è¶‹åŠ¿å¤±è´¥: {e}")
            continue
    
    # æ’åº
    if trend_results:
        trend_results.sort(key=lambda x: x['trend_score'], reverse=True)
        logger.info(f"æˆåŠŸè®¡ç®— {len(trend_results)} ä¸ªæ¿å—çš„è¶‹åŠ¿")
    else:
        logger.warning("æœªèƒ½è®¡ç®—ä»»ä½•æ¿å—çš„è¶‹åŠ¿")
    
    # 5. ç”Ÿæˆå›¾è¡¨
    logger.info("\nç”Ÿæˆè¶‹åŠ¿å›¾è¡¨...")
    chart_files = []
    
    # ç”Ÿæˆæ•´ä½“å¸‚åœºè¶‹åŠ¿å›¾
    trend_chart = chart_gen.generate_top_sectors_trend(top_n=5, days=47)
    if trend_chart:
        chart_files.append(trend_chart)
        logger.info(f"  âœ“ TOP5è¶‹åŠ¿å›¾: {trend_chart}")
    
    # ç”Ÿæˆçƒ­åŠ›å›¾
    heatmap_chart = chart_gen.generate_market_heatmap(days=20)
    if heatmap_chart:
        chart_files.append(heatmap_chart)
        logger.info(f"  âœ“ çƒ­åŠ›å›¾: {heatmap_chart}")
    
    # ç”Ÿæˆå•ä¸ªæ¿å—å†å²å›¾ï¼ˆæœ€å¼ºå’Œæœ€å¼±å„2ä¸ªï¼‰
    if trend_results and len(trend_results) >= 4:
        sectors_to_chart = [
            trend_results[0]['sector'], 
            trend_results[1]['sector'], 
            trend_results[-1]['sector'], 
            trend_results[-2]['sector']
        ]
        for sector in sectors_to_chart:
            try:
                chart_path = chart_gen.generate_sector_history_chart(sector, df=historical_df, days=47)
                if chart_path:
                    chart_files.append(chart_path)
                    logger.info(f"  âœ“ {sector}å†å²å›¾")
            except Exception as e:
                logger.warning(f"ç”Ÿæˆ {sector} å›¾è¡¨å¤±è´¥: {e}")
    
    # 6. ç”ŸæˆMarkdownæŠ¥å‘Š
    logger.info("\nç”ŸæˆæŠ¥å‘Š...")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    unique_dates = historical_df['date'].nunique() if 'date' in historical_df.columns else 0
    total_records = len(historical_df)
    
    report_lines = [
        f"# ğŸ“Š æ¿å—èµ„é‡‘æµå‘å†å²åˆ†ææŠ¥å‘Š",
        f"",
        f"**åˆ†æå‘¨æœŸ**: {start_date} è‡³ {end_date}",
        f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
        f"**æ•°æ®èŒƒå›´**: æ¿å—å†å²èµ„é‡‘æµï¼ˆæ—¥çº§åˆ«ï¼‰",
        f"**äº¤æ˜“æ—¥æ•°é‡**: {unique_dates} å¤©",
        f"**æ•°æ®è®°å½•**: {total_records} æ¡",
        f"",
        f"---",
        f"",
    ]
    
    if trend_results:
        report_lines.extend([
            f"## ğŸ”¥ TOP10 æ¿å—è¶‹åŠ¿æ’å",
            f"",
            "| æ’å | æ¿å— | è¶‹åŠ¿å¾—åˆ† | æ–¹å‘ | å¹³å‡å‡€æµå…¥ | ä¸Šæ¶¨ä¸€è‡´æ€§ |",
            "|------|------|----------|------|------------|------------|",
        ])
        
        for i, r in enumerate(trend_results[:10], 1):
            direction_icon = "ğŸ“ˆ" if r['direction'] == 'up' else "ğŸ“‰" if r['direction'] == 'down' else "â¡ï¸"
            report_lines.append(
                f"| {i} | {r['sector']} | {r['trend_score']:.1f} | {direction_icon} {r['direction']} | "
                f"{r['avg_inflow']/1e8:.2f}äº¿ | {r['consistency']:.0%} |"
            )
        
        report_lines.extend([
            f"",
            f"---",
            f"",
            f"## ğŸ† å¼ºåŠ¿æ¿å—ï¼ˆè¶‹åŠ¿å¾—åˆ† > 20ï¼‰",
            f"",
        ])
        
        strong_sectors = [r for r in trend_results if r['trend_score'] > 20]
        if strong_sectors:
            for r in strong_sectors[:5]:
                report_lines.append(f"- **{r['sector']}**: å¾—åˆ† {r['trend_score']:.1f}ï¼Œå¹³å‡å‡€æµå…¥ {r['avg_inflow']/1e8:.2f}äº¿")
        else:
            report_lines.append("æš‚æ— å¼ºåŠ¿æ¿å—")
        
        report_lines.extend([
            f"",
            f"## âš ï¸ å¼±åŠ¿æ¿å—ï¼ˆè¶‹åŠ¿å¾—åˆ† < -20ï¼‰",
            f"",
        ])
        
        weak_sectors = [r for r in trend_results if r['trend_score'] < -20]
        if weak_sectors:
            for r in weak_sectors[-5:]:
                report_lines.append(f"- **{r['sector']}**: å¾—åˆ† {r['trend_score']:.1f}ï¼Œå¹³å‡å‡€æµå…¥ {r['avg_inflow']/1e8:.2f}äº¿")
        else:
            report_lines.append("æš‚æ— å¼±åŠ¿æ¿å—")
    else:
        report_lines.extend([
            f"## âš ï¸ è¶‹åŠ¿åˆ†æ",
            f"",
            f"æœªèƒ½è®¡ç®—æ¿å—è¶‹åŠ¿ï¼Œè¯·æ£€æŸ¥æ•°æ®å®Œæ•´æ€§ã€‚",
            f"",
        ])
    
    # å…³é”®å‘ç°
    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## ğŸ“ˆ å…³é”®å‘ç°",
        f"",
        f"1. **åˆ†ææœŸé—´å…± {unique_dates} ä¸ªäº¤æ˜“æ—¥**",
    ])
    
    if trend_results:
        strong_sectors = [r for r in trend_results if r['trend_score'] > 20]
        weak_sectors = [r for r in trend_results if r['trend_score'] < -20]
        report_lines.extend([
            f"2. **è¶‹åŠ¿æœ€å¼ºæ¿å—**: {trend_results[0]['sector']} (å¾—åˆ†: {trend_results[0]['trend_score']:.1f})",
            f"3. **è¶‹åŠ¿æœ€å¼±æ¿å—**: {trend_results[-1]['sector']} (å¾—åˆ†: {trend_results[-1]['trend_score']:.1f})",
            f"4. **å¼ºåŠ¿æ¿å—æ•°é‡**: {len(strong_sectors)} ä¸ª",
            f"5. **å¼±åŠ¿æ¿å—æ•°é‡**: {len(weak_sectors)} ä¸ª",
        ])
    else:
        report_lines.append(f"2. **è¶‹åŠ¿åˆ†æ**: æš‚æ— æ³•è®¡ç®—")
    
    report_lines.extend([
        f"",
        f"---",
        f"",
        f"## ğŸ“Š å›¾è¡¨è¯´æ˜",
        f"",
        f"æœ¬æŠ¥å‘ŠåŒ…å«ä»¥ä¸‹å›¾è¡¨ï¼š",
        f"- TOP5æ¿å—èµ„é‡‘æµå‘è¶‹åŠ¿å›¾",
        f"- æ¿å—èµ„é‡‘æµå‘çƒ­åŠ›å›¾ï¼ˆè¿‘20å¤©ï¼‰",
    ])
    
    if trend_results and len(trend_results) >= 4:
        report_lines.append(f"- æœ€å¼º/æœ€å¼±æ¿å—å†å²è¶‹åŠ¿å›¾")
    
    report_lines.append(f"")
    
    report_content = '\n'.join(report_lines)
    
    # 7. å†™å…¥Notion
    logger.info("\nå†™å…¥Notion...")
    title = f"ğŸ“Š æ¿å—èµ„é‡‘æµå‘å†å²åˆ†æ - {start_date} è‡³ {end_date}"
    
    try:
        page_id = notion.write_report(
            title=title,
            content=report_content,
            chart_files=chart_files
        )
        
        if page_id:
            logger.info(f"âœ… æŠ¥å‘Šå·²æˆåŠŸå†™å…¥Notion!")
            logger.info(f"   é¡µé¢ID: {page_id}")
            return True
        else:
            logger.error("å†™å…¥Notionå¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"å†™å…¥Notionå¤±è´¥: {e}")
        return False

if __name__ == '__main__':
    success = asyncio.run(generate_historical_report())
    sys.exit(0 if success else 1)
